{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "time_series.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajanieprabha/HackZurich/blob/master/time_series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Pmxv2ioyCRw"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "b-2ShX25yNWf",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pa49bUnKyRgF"
      },
      "source": [
        "# Time series forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "11Ilg92myRcw"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/time_series\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7rZnJaGTWQw0",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxvx3SB2bCYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSq798mjk805",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### ENTER THE NAME OF LOCATION YOU WANT TO GET THE MODEL FOR \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-x-GgENynHdx",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEcVxNK3iZBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parking_locations = []\n",
        "for filename in glob.glob('/content/gdrive/My Drive/Archive/*.csv'):\n",
        "  location = filename.split(\"/\")[5].split(\"-\")[0]\n",
        "  if location not in parking_locations:\n",
        "    parking_locations.append(location)\n",
        "\n",
        "print(parking_locations)\n",
        "print(len(parking_locations))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkC5BktcnARq",
        "colab_type": "text"
      },
      "source": [
        "## Check list uniqueness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT1NLnr9m9bC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"The original list is : \" + str(parking_locations)) \n",
        "  \n",
        "flag = 0\n",
        "  \n",
        "# using set() + len() \n",
        "# to check all unique list elements \n",
        "flag = len(set(parking_locations)) == len(parking_locations) \n",
        "  \n",
        "  \n",
        "# printing result \n",
        "if(flag) : \n",
        "    print (\"List contains all unique elements\") \n",
        "else :  \n",
        "    print (\"List contains does not contains all unique elements\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7uUt1gjoY7b",
        "colab_type": "text"
      },
      "source": [
        "## Read csv files for one location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDKjt0doodto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = []\n",
        "for filename in glob.glob('/content/gdrive/My Drive/Archive/*.csv'):\n",
        "  if parking_locations[29] == filename.split(\"/\")[5].split(\"-\")[0]:\n",
        "    print(filename)\n",
        "    data.append(pd.read_csv(filename, names = ['Date', 'free'], index_col='Date', parse_dates=True))\n",
        "\n",
        "data = pd.concat(data)\n",
        "    \n",
        "data.sort_index(inplace=True)\n",
        "print(len(data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VdbOWXiTWM2T"
      },
      "source": [
        "Let's take a glance at the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBq2ivkdQqvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ojHE-iCCWIhz",
        "colab": {}
      },
      "source": [
        "\n",
        "out_of_service_count = 0\n",
        "itera = 0 \n",
        "service_off = False\n",
        "remove_these = []\n",
        "for index_1, row in data.iterrows():\n",
        "  if row['free'] == 0:\n",
        "    out_of_service_count += 1\n",
        "    if out_of_service_count > 60 and not service_off:\n",
        "      service_off=True\n",
        "      start_ind = itera-60\n",
        "      #start_time = data.iloc[itera-60].index\n",
        "      for i in range(itera-60,itera+1):\n",
        "        \n",
        "        remove_these.append(i)\n",
        "  \n",
        "      \n",
        "  elif service_off:\n",
        "    #end_time = data.iloc[itera]\n",
        "    end_index = itera\n",
        "    remove_these.append(itera)\n",
        "    #print(start_time, end_time)\n",
        "\n",
        "    #data.loc[~data.index.isin(data.index[data.index.slice_indexer(start_time, end_time)])]\n",
        "    #data.drop(start_time)\n",
        "    out_of_service_count = 0\n",
        "      \n",
        "      \n",
        "  else:\n",
        "    out_of_service_count = 0\n",
        "  \n",
        "  itera += 1\n",
        "      \n",
        "    \n",
        "print(remove_these)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGwVmsLDVW3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop(data.index[remove_these])\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qfbpcV0MWQzl"
      },
      "source": [
        "As you can see above, an observation is recorded every 10 mintues. This means that, for a single hour, you will have 6 observations. Similarly, a single day will contain 144 (6x24) observations. \n",
        "\n",
        "Given a specific time, let's say you want to predict the free spots 6 hours in the future. In order to make this prediction, you choose to use 5 days of observations. Thus, you would create a window containing the last 720(5x144) observations to train the model. Many such configurations are possible, making this dataset a good one to experiment with.\n",
        "\n",
        "The function below returns the above described windows of time for the model to train on. The parameter `history_size` is the size of the past window of information. The `target_size` is how far in the future does the model need to learn to predict. The `target_size` is the label that needs to be predicted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdNGhC5lXuYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7AoxQuTrWIbi",
        "colab": {}
      },
      "source": [
        "def univariate_data(dataset, start_index, end_index, history_size, target_size):\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  start_index = start_index + history_size\n",
        "  if end_index is None:\n",
        "    end_index = len(dataset) - target_size\n",
        "\n",
        "  for i in range(start_index, end_index):\n",
        "    indices = range(i-history_size, i)\n",
        "    # Reshape data from (history_size,) to (history_size, 1)\n",
        "    data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
        "    labels.append(dataset[i+target_size])\n",
        "  return np.array(data), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qoFJZmXBaxCc"
      },
      "source": [
        "In both the following tutorials, the first 300,000 rows of the data will be the training dataset, and there remaining will be the validation dataset. This amounts to ~2100 days worth of training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ia-MPAHxbInX",
        "colab": {}
      },
      "source": [
        "TRAIN_SPLIT = 300000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EowWDtaNnH1y"
      },
      "source": [
        "Setting seed to ensure reproducibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8YEwr-NoWUpV"
      },
      "source": [
        "## Part 1: Forecast a univariate time series\n",
        "First, you will train a model using only a single feature (temperature), and use it to make predictions for that value in the future.\n",
        "\n",
        "Let's first extract only the temperature from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qVukM9dRipop",
        "colab": {}
      },
      "source": [
        "def create_time_steps(length):\n",
        "  time_steps = []\n",
        "  for i in range(-length, 0, 1):\n",
        "    time_steps.append(i)\n",
        "  return time_steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QQeGvh7cWXMR",
        "colab": {}
      },
      "source": [
        "def show_plot(plot_data, delta, title):\n",
        "  labels = ['History', 'True Future', 'Model Prediction']\n",
        "  marker = ['.-', 'rx', 'go']\n",
        "  time_steps = create_time_steps(plot_data[0].shape[0])\n",
        "  if delta:\n",
        "    future = delta\n",
        "  else:\n",
        "    future = 0\n",
        "\n",
        "  plt.title(title)\n",
        "  for i, x in enumerate(plot_data):\n",
        "    if i:\n",
        "      plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
        "               label=labels[i])\n",
        "    else:\n",
        "      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "  plt.legend()\n",
        "  plt.xlim([time_steps[0], (future+5)*2])\n",
        "  plt.xlabel('Time-Step')\n",
        "  return plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b5rUJ_2YMWzG"
      },
      "source": [
        "### Baseline\n",
        "Before proceeding to train a model, let's first set a simple baseline. Given an input point, the baseline method looks at all the history and predicts the next point to be the average of the last 20 observations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P9nYWcxMMWnr",
        "colab": {}
      },
      "source": [
        "def baseline(history):\n",
        "  return np.mean(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "067m6t8cMakb"
      },
      "source": [
        "Let's see if you can beat this baseline using a recurrent neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "### Recurrent neural network\n",
        "\n",
        "A Recurrent Neural Network (RNN) is a type of neural network well-suited to time series data. RNNs process a time series step-by-step, maintaining an internal state summarizing the information they've seen so far. For more details, read the [RNN tutorial](https://www.tensorflow.org/tutorials/sequences/recurrent). In this tutorial, you will use a specialized RNN layer called Long Short Term Memory ([LSTM](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM))\n",
        "\n",
        "Let's now use `tf.data` to shuffle, batch, and cache the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kk-evkrmMWh9",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "BUFFER_SIZE = 10000\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4nagdTRNfPuZ"
      },
      "source": [
        "You will see the LSTM requires the input shape of the data it is being given."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0opH9xi5MtIk",
        "colab": {}
      },
      "source": [
        "EVALUATION_INTERVAL = 200\n",
        "EPOCHS = 10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DphrB7bxSNDd",
        "colab": {}
      },
      "source": [
        "#features_considered = ['p (mbar)', 'T (degC)', 'rho (g/m**3)']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IfQUSiJfUpXJ",
        "colab": {}
      },
      "source": [
        "features_considered = ['free']\n",
        "features = data[features_considered]\n",
        "features.index = data.index\n",
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qSfhTZi5r15R"
      },
      "source": [
        "Let's have a look at how each of these features vary across time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QdgC8zvGr21X",
        "colab": {}
      },
      "source": [
        "features.plot(subplots=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cqStgZ-O1b3_"
      },
      "source": [
        "As mentioned, the first step will be to normalize the dataset using the mean and standard deviation of the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W7VuNIwfHRHx",
        "colab": {}
      },
      "source": [
        "dataset = features.values\n",
        "#print(dataset)\n",
        "data_mean = dataset.mean(axis=0)\n",
        "data_std = dataset.std(axis=0)\n",
        "print(data_std)\n",
        "print(data_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eJUeWDqploCt",
        "colab": {}
      },
      "source": [
        "dataset = (dataset-data_mean)/data_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhsPTe3uy7ZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dataset)\n",
        "print(len(dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LyuGuJUgjUK3"
      },
      "source": [
        "### Single step model\n",
        "In a single step setup, the model learns to predict a single point in the future based on some history provided.\n",
        "\n",
        "The below function performs the same windowing task as below, however, here it samples the past observation based on the step size given."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d-rVX4d3OF86",
        "colab": {}
      },
      "source": [
        "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
        "                      target_size, step, single_step=False):\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  start_index = start_index + history_size\n",
        "  if end_index is None:\n",
        "    end_index = len(dataset) - target_size\n",
        "\n",
        "  for i in range(start_index, end_index):\n",
        "    indices = range(i-history_size, i, step)\n",
        "    data.append(dataset[indices])\n",
        "\n",
        "    if single_step:\n",
        "      labels.append(target[i+target_size])\n",
        "    else:\n",
        "      labels.append(target[i:i+target_size])\n",
        "\n",
        "  return np.array(data), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HWVGYwbN2ITI"
      },
      "source": [
        "In this tutorial, the network is shown data from the last five (5) days, i.e. 720 observations that are sampled every hour. The sampling is done every one hour since a drastic change is not expected within 60 minutes. Thus, 120 observation represent history of the last five days.  For the single step prediction model, the label for a datapoint is the temperature 12 hours into the future. In order to create a label for this, the temperature after 72(12*6) observations is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HlhVGzPhmMYI",
        "colab": {}
      },
      "source": [
        "past_history = 1000\n",
        "future_target = 72\n",
        "STEP = 6\n",
        "\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CamMObrwPhnp"
      },
      "source": [
        "Let's look at a single data-point.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ZAdeAnP5c72",
        "colab": {}
      },
      "source": [
        "def plot_train_history(history, title):\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(loss))\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  plt.title(title)\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2GnE087bJYSu"
      },
      "source": [
        "### Multi-Step model\n",
        "In a multi-step prediction model, given a past history, the model needs to learn to predict a range of future values. Thus, unlike a single step model, where only a single future point is predicted, a multi-step model predict a sequence of the future.\n",
        "\n",
        "For the multi-step model, the training data again consists of recordings over the past five days sampled every hour. However, here, the model needs to learn to predict the temperature for the next 12 hours. Since an obversation is taken every 10 minutes, the output is 72 predictions. For this task, the dataset needs to be prepared accordingly, thus the first step is just to create it again, but with a different target window."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kZCk9fqyJZqX",
        "colab": {}
      },
      "source": [
        "future_target = 72\n",
        "x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:,0], 0,\n",
        "                                                 TRAIN_SPLIT, past_history,\n",
        "                                                 future_target, STEP)\n",
        "x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:,0],\n",
        "                                             TRAIN_SPLIT, None, past_history,\n",
        "                                             future_target, STEP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LImXPwAGRtWy"
      },
      "source": [
        "Let's check out a sample data-point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpWDcBkQRwS-",
        "colab": {}
      },
      "source": [
        "print ('Single window of past history : {}'.format(x_train_multi[0].shape))\n",
        "print ('\\n Target temperature to predict : {}'.format(y_train_multi[0].shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cjR4PJArMOpA",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "BUFFER_SIZE = 10000\n",
        "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
        "train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\n",
        "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
        "val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IZcg8FWpSG8K"
      },
      "source": [
        "Plotting a sample data-point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ksXKVbwBV7D3",
        "colab": {}
      },
      "source": [
        "def multi_step_plot(history, true_future, prediction):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  num_in = create_time_steps(len(history))\n",
        "  num_out = len(true_future)\n",
        "  plt.plot(num_in, np.array(history[:,0]), label='History')\n",
        "  plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n",
        "           label='True Future')\n",
        "  if prediction.any():\n",
        "    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n",
        "             label='Predicted Future')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LCQKetflZRMF"
      },
      "source": [
        "In this plot and subsequent similar plots, the history and the future data are sampled every hour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R6G8bacQR4w2",
        "colab": {}
      },
      "source": [
        "print(train_data_multi)\n",
        "for x, y in train_data_multi:\n",
        "  multi_step_plot(x[0], y[0], np.array([0]))\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XOjz8DzZ4HFS"
      },
      "source": [
        "Since the task here is a bit more complicated than the previous task, the model now consists of two LSTM layers. Finally, since 72 predictions are made, the dense layer outputs 72 predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "byAl0NKSNBP6",
        "colab": {}
      },
      "source": [
        "\n",
        "multi_step_model = tf.keras.models.Sequential()\n",
        "multi_step_model.add(tf.keras.layers.LSTM(32,\n",
        "                                          return_sequences=True,\n",
        "                                          input_shape=x_train_multi.shape[-2:]))\n",
        "                                   \n",
        "multi_step_model.add(tf.keras.layers.LSTM(32, return_sequences=True))\n",
        "multi_step_model.add(tf.keras.layers.LSTM(32, return_sequences=True))\n",
        "multi_step_model.add(tf.keras.layers.LSTM(16))\n",
        "multi_step_model.add(tf.keras.layers.Dense(72))\n",
        "\n",
        "multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UvB7zBqVSMyl"
      },
      "source": [
        "Let's see how the model predicts before it trains."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "13_ZWvB9SRlZ",
        "colab": {}
      },
      "source": [
        "for x, y in val_data_multi.take(1):\n",
        "  print (multi_step_model.predict(x).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7uwOhXo3Oems",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "EVALUATION_INTERVAL = 500\n",
        "\n",
        "multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n",
        "                                          steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                                          validation_data=val_data_multi,\n",
        "                                          validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UKfQoBjQ5l7U",
        "colab": {}
      },
      "source": [
        "plot_train_history(multi_step_history, 'Multi-Step Training and validation loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nnUTRK03IrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(val_data_multi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-SpZT-47iWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x[1])\n",
        "  #break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oDg94-yq4pas"
      },
      "source": [
        "#### Predict a multi-step future\n",
        "Let's now have a look at how well your network has learnt to predict the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dt22wq6fyIBU",
        "colab": {}
      },
      "source": [
        "for x, y in val_data_multi:\n",
        "  #print(x.shape, y.shape)\n",
        "  multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0])\n",
        "  #break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1un5ONl1y_O5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_step_model.save('/content/gdrive/My Drive/zuerichparkhaushardauii.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-c0mT7J0xI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tf.enable_eager_execution()\n",
        "new_model = tf.keras.models.load_model('/content/gdrive/My Drive/zuerichparkhaushardauii.h5')\n",
        "x_test = tf.random.uniform((1,84,1),minval=0,maxval=200)\n",
        "y_test = tf.random.uniform((1,72),minval=0,maxval=200)\n",
        "\n",
        "\n",
        "test_data_multi = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_data_multi = test_data_multi.cache().shuffle(1000).batch(1).repeat()\n",
        "for x, y in test_data_multi:\n",
        "  multi_step_plot(x[0], y[0], new_model.predict(x, steps=1)[0]*data_std+data_mean)\n",
        "  break\n",
        "\n",
        "\n",
        "\n",
        "#p = (new_model.predict(x_test, steps=1))\n",
        "#print(p*data_std+data_mean)\n",
        "#multi_step_plot(x_test, y_test, p)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}